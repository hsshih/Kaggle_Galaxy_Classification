{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Galaxy_Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOQOIE4e1VlW2/l+uWyDdFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsshih/Kaggle_Galaxy_Classification/blob/main/Galaxy_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VklXO2RnAf3m"
      },
      "source": [
        "# importing libraries\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, GlobalMaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import model_from_json\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2enKFJ70AlUu"
      },
      "source": [
        "def get_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (2, 2), input_shape = input_shape))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size =(2, 2)))\n",
        "    \n",
        "    model.add(Conv2D(32, (2, 2)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size =(2, 2)))\n",
        "    \n",
        "    model.add(Conv2D(64, (2, 2)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size =(2, 2)))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    \n",
        "    return(model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFkzdb5lAnQy"
      },
      "source": [
        "def main():\n",
        "\n",
        "    img_width, img_height = 212, 212\n",
        "\n",
        "    train_data_dir = 'data/train'\n",
        "    validation_data_dir = 'data/test'\n",
        "    nb_train_samples = 400\n",
        "    nb_validation_samples = 100\n",
        "    epochs = 10\n",
        "    batch_size = 16\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        input_shape = (3, img_width, img_height)\n",
        "    else:\n",
        "        input_shape = (img_width, img_height, 3)\n",
        "\n",
        "    model = get_model(input_shape)\n",
        "\n",
        "    model.compile(loss ='binary_crossentropy',\n",
        "                  optimizer ='rmsprop',\n",
        "                  metrics =['accuracy'])\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "                                       rescale = 1. / 255,\n",
        "                                       shear_range = 0.2,\n",
        "                                       zoom_range = 0.2,\n",
        "                                       horizontal_flip = True)\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                        target_size =(img_width, img_height),\n",
        "                                                        batch_size = batch_size, class_mode ='binary')\n",
        "\n",
        "    validation_generator = test_datagen.flow_from_directory(\n",
        "                                                            validation_data_dir,\n",
        "                                                            target_size =(img_width, img_height),\n",
        "                                                            batch_size = batch_size, class_mode ='binary') \n",
        "\n",
        "    model.fit_generator(train_generator, \n",
        "                        steps_per_epoch = nb_train_samples // batch_size, \n",
        "                        epochs = epochs, validation_data = validation_generator, \n",
        "                        validation_steps = nb_validation_samples // batch_size) \n",
        "\n",
        "\n",
        "    # serialize model to JSON\n",
        "    model_json = model.to_json()\n",
        "    with open(\"model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    # serialize weights to HDF5\n",
        "    model.save_weights(\"model.h5\")\n",
        "    print(\"Saved model to disk\")\n",
        "\n",
        "    # load json and create model\n",
        "    json_file = open('model.json', 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    # load weights into new model\n",
        "    loaded_model.load_weights(\"model.h5\")\n",
        "    print(\"Loaded model from disk\")\n",
        "\n",
        "    # evaluate loaded model on test data\n",
        "    loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    score = loaded_model.evaluate(validation_generator, verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}